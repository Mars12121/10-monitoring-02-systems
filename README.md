
# Домашнее задание к занятию "13.Системы мониторинга" - Морозов Александ

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

Ответ:
Загрузка CPU и RAM— загруженность сервера. Свободное место на диске — отчёты сохраняются на диск, важно не допустить его заполнения.
HTTP-доступность  — доступность сервиса. Время отклика сервиса — загруженность. Состояние сервиса (up/down) — состояние.

#
2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?

Ответ:
1. RAM - объем оперативной памяти, который всего/занято/свободно
2. inode - это структура данных файловой системы Unix-подобных операционных систем, содержащая важную метаинформацию о файле или директории, такую как права доступа, владелец файла, размер, временные отметки изменения и модификации, а также адрес физического расположения данных на носителе. В большинстве файловых систем есть ограничение на максимальное количество inodes, доступных для хранения объектов. Когда лимит достигнут, невозможно создать новые файлы или каталоги, несмотря на оставшееся свободное место на диске.
3. LA (Load Average) — это метрика, отображающая среднюю нагрузку на систему за определенный промежуток времени. Складывется из нескольких параметров загрузка CPU, количество операций I/O диска, загрузка сетевого интерфейса.

Предложить менеджеру внедрить следующие показатели:

1. SLA - это соглашение об уровне обслуживания, документально закрепленное обязательство поставщика услуги обеспечить определенное качество предоставления услуг клиенту. Такие соглашения помогают формализовать ожидания обеих сторон и установить чёткие критерии оценки выполнения обязательств.

2. SLO (Service Level Objective) — это конкретные цели, устанавливаемые внутри организации или соглашения между сторонами, направленные на достижение определенного уровня качества обслуживания. Они представляют собой численные индикаторы, которые компания обязуется соблюдать в рамках своей работы или предоставляемых услуг.

3. SLI (Service Level Indicator) — это показатель, используемый для определения текущего состояния качества обслуживания, предоставляемого сервисом или продуктом.
   Latency (задержка): Измеряет время, затраченное на получение ответа от сервиса. Цель может заключаться в обеспечении задержки менее определенной величины (например, 50 мс).
   Error rate (частота ошибок): Определяет процент неудачно завершившихся запросов. Желаемое значение может быть установлено как максимум 0,1% ошибок.
   Throughput (пропускная способность): Оценивает количество запросов, обслуживаемых системой за единицу времени.Например, цель может звучать как обслуживание 10 тысяч запросов в минуту.
   Availability (доступность): Фиксирует продолжительность времени, в течение которого сервис функционирует должным образом. Обычно указывается как процент времени бесперебойной работы (например, 99,0%).


#
3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?

Ответ:
Необходимо настроить сбор и анализ логов на open source решениях(ELK, greylog, rsyslog + bash скрипты и т.д.). Для этого необходим, что бы разработка включила логирование в приложении стандартный вывод (stdout или stderr), с уровнем логирования INFO.


#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

Ответ:
Существуют 5 категорий http-response. Информационный ответ (1ХХ), успешное выполнение (2ХХ), сообщения о перенаправлении (3ХХ), ошибка на стороне клиента (4ХХ), ошибка на стороне сервера (5ХХ). Если мы считаем успешным всё, что не 4ХХ и 5ХХ, то нужно использовать формулу: (summ_1xx_requests + summ_2xx_requests + summ_3xx_requests)/summ_all_requests.

5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#

Ответ:
Pull-модель мониторинга
    В Pull-модели центральный сервер мониторинга периодически опрашивает (запрашивает) метрики у агентов или сервисов.
  Плюсы Pull-модели:

    - Простота управления:  
      Централизованное управление сбором метрик на сервере мониторинга. Легко изменять частоту запросов, добавлять или удалять цели мониторинга без изменения конфигурации агентов.

    - Простота масштабирования:  
      Легко добавлять новые цели мониторинга, просто указав их на центральном сервере.

    - Автоматическое обнаружение проблем:  
      Если агент или сервис перестал отвечать, сервер мониторинга сразу узнает об этом, так как не сможет получить данные при следующем запросе.

    - Удобство реализации сервис-дискавери:  
      Удобно использовать автоматическое обнаружение новых сервисов (например, Kubernetes service discovery).

    - Безопасность:  
      Нет необходимости открывать дополнительные порты на агентах для отправки данных наружу. Данные запрашиваются сервером мониторинга, что позволяет лучше контролировать сетевые соединения и безопасность.

  Минусы Pull-модели:

    - Сложность работы с кратковременными событиями:  
      Если событие произошло и исчезло между двумя запросами, оно может быть пропущено.

    - Проблемы с NAT и Firewall:  
      Сервер мониторинга должен иметь доступ к агентам, что иногда затруднено в сетях с NAT или строгими firewall-правилами.

    - Нагрузка на сервер мониторинга:  
      Сервер мониторинга должен самостоятельно опрашивать большое количество целей, что может создавать нагрузку на сеть и сервер.

---

  Push-модель мониторинга

    В Push-модели агенты или сервисы сами отправляют (push) свои метрики на центральный сервер мониторинга.

  Плюсы Push-модели:

    - Подходит для кратковременных событий:  
      Позволяет отправлять события сразу после их возникновения, что минимизирует вероятность пропуска важных данных.

    - Удобство работы в динамических окружениях:  
      Легко интегрировать с временными или динамическими средами (например, контейнеры, serverless), где серверу мониторинга сложно постоянно отслеживать наличие новых объектов.

    - Удобство работы с NAT и Firewall:  
      Агент инициирует соединение сам, что упрощает прохождение через NAT и firewall.

    - Гибкость отправки данных:  
      Агент может отправлять данные по мере их появления или пакетами в удобное время (например, при низкой нагрузке).

  Минусы Push-модели:

    - Отсутствие встроенного контроля доступности агентов:  
      Если агент перестал отправлять данные, сервер мониторинга не всегда сразу заметит это (необходимы дополнительные механизмы контроля).

    - Безопасность и управление доступом:  
      Сервер должен принимать входящие соединения от множества агентов. Это требует более сложной настройки безопасности и управления доступом.

    - Сложность масштабирования конфигурации агентов:  
      При изменении параметров сбора метрик необходимо менять конфигурацию каждого агента отдельно, что может быть неудобно при большом количестве агентов.


6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios

Ответ:
  - Prometheus  
    Pull (основная модель), но есть возможность использовать и Push через дополнительный компонент — Pushgateway.  
  
  Итог: Pull (основная), но возможен гибридный подход.

  - TICK stack (Telegraf, InfluxDB, Chronograf, Kapacitor)    
    - Telegraf собирает и отправляет данные в InfluxDB (Push).  
    - InfluxDB принимает входящие данные (Push).  
    - Kapacitor может как получать данные из InfluxDB, так и принимать напрямую от агентов (Push).  
  Итог: Push-модель.

  - Zabbix  
    - Zabbix-агенты могут работать в активном режиме (Push) и пассивном режиме (Pull).  
    - Также можно использовать SNMP, IPMI и другие протоколы с Pull-подходом.  
  Итог: Гибридная модель.

  - VictoriaMetrics  
    - Совместима с протоколом Prometheus и может выполнять Pull-запросы (как Prometheus).  
    - Также поддерживает прием данных по Push-протоколам (например, через Remote Write API).  
  Итог: Гибридная модель.

  - Nagios  
    В основном Pull-модель, но также может использовать Push через дополнения (например, NRDP, NSCA).  
  Итог: Pull (основная), но возможен гибридный подход.

#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`

Ответ:
![alt text](https://github.com/Mars12121/10-monitoring-02-systems/blob/main/img/1.png)

#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.

Ответ:
![alt text](https://github.com/Mars12121/10-monitoring-02-systems/blob/main/img/2.png)

#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

Ответ:
![alt text](https://github.com/Mars12121/10-monitoring-02-systems/blob/main/img/3.png)

## Дополнительное задание (со звездочкой*) - необязательно к выполнению

1. Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

2. В веб-интерфейсе откройте вкладку `Dashboards`. Попробуйте создать свой dashboard с отображением:

    - утилизации ЦПУ
    - количества использованного RAM
    - утилизации пространства на дисках
    - количество поднятых контейнеров
    - аптайм
    - ...
    - фантазируйте)
    
    ---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
